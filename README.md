[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/Lj3YlzJp)
# Proyecto Final 2025-1: AI Neural Network
## **CS2013 Programaci√≥n III** ¬∑ Informe Final

### **Descripci√≥n**

> Ejemplo: Implementaci√≥n de una red neuronal multicapa en C++ para clasificaci√≥n de d√≠gitos manuscritos.

### Contenidos

1. [Datos generales](#datos-generales)
2. [Requisitos e instalaci√≥n](#requisitos-e-instalaci√≥n)
3. [Investigaci√≥n te√≥rica](#1-investigaci√≥n-te√≥rica)
4. [Dise√±o e implementaci√≥n](#2-dise√±o-e-implementaci√≥n)
5. [Ejecuci√≥n](#3-ejecuci√≥n)
6. [An√°lisis del rendimiento](#4-an√°lisis-del-rendimiento)
7. [Trabajo en equipo](#5-trabajo-en-equipo)
8. [Conclusiones](#6-conclusiones)
9. [Bibliograf√≠a](#7-bibliograf√≠a)
10. [Licencia](#licencia)
---

### Datos generales

* **Tema**: Redes Neuronales en AI
* **Grupo**: `group_3_custom_name`
* **Integrantes**:

  * Matos Copello Rayhan Derek ‚Äì 202410377 (Responsable de investigaci√≥n te√≥rica)
  * Tamara Ureta, Anyeli Azumi ‚Äì 202410590 (Responsable de investigaci√≥n te√≥rica)
  * Alvarado Le√≥n, Adriana Celeste ‚Äì 209900002 (Dise√±o e implementaci√≥n)
  * Mattos Gutierrez, Angel Daniel ‚Äì 202420199 (Implementaci√≥n del modelo)
  * Aquino Castro Farid Jack ‚Äì 202410569 (An√°lisis y Rendimiento)
  * Portugal Vilca Julio Cesar ‚Äì 202410487 (Documentaci√≥n y demo)
> **Nota**: El informe completo se encuentra adjunto en el repositorio del proyecto.
---

### Requisitos e instalaci√≥n

1. **Compilador**: GCC 11 o superior, Clang 19 o superior
2. **Dependencias**:\
  **Generales:**
   * CMake 3.12+
   * OpenCV 4.6.0+
   * OpenMP (Incluido en GCC, instalaci√≥n adicional en Clang)
   * FFmpeg 7.0+
     
   **Linux:**
   * Xlib (libX11) 
   * libpipewire 0.3+
3. **Instalaci√≥n**:

   ```bash
   git clone https://github.com/CS1103/projecto-final-conciencia.git
   cd proyecto-final
   mkdir build && cd build
   cmake ..
   make
   ```

Al compilar, encontrar√°s con el ejecutable principal (popn_ai) y dos carpetas adicionales.
- (generator/popn_generator) Generador de im√°genes
- (tests/batch_evaluator) Test de datos de prueba
- (tests/image_evaluator) Test de reconocimiento de im√°genes
- (tests/gameplay_evaluator) Test de gameplay (requiere una ROM de Pop'n Music 10 y el emulador PCSX2)

#### Configuracion del emulador PCSX2 (gameplay_evaluator)
En el apartado gr√°fico, configurar la secci√≥n de Renderizado (Rendering), para cambiar la resoluci√≥n nativa del emulador a 3x Nativo (~1080px/FHD). Adicionalmente, en el apartado de controladores, cambiar el de PlayStation 2 por un control de Pop'n Music y configurarlo de la siguiente manera:
```
  F   G   H   J
C   V   B   N   M
```
Puedes guiarte a partir del orden que se muestra en el menu de el emulador. De lo contrario, no va a funcionar el test de gameplay.

---

### 1. Investigaci√≥n te√≥rica

**Objetivo General**:

* Desarrollar una red neuronal que pueda predecir los 512 posibles patrones basados en las im√°genes del videojuego Pop‚Äôn Music.

**Objetivos espec√≠ficos**

* Crear las clases Tensor, IOptimizer, ILayer, Neural Network,  y ILoss. 
* Crear sus clases hijas ReLU, Dense, MSELoss, BCELoss, CrossEntropyLoss, SGD,  Adam. 
* Crear im√°genes con diferentes patrones para el entrenamiento de la red. 
* Obtener los pesos calculados para realizar los test y calcular la precisi√≥n del modelo.

## Marco Te√≥rico

### 1.1 Redes Neuronales Artificiales

Las redes neuronales artificiales (RNA) son simulaciones inform√°ticas basadas en el funcionamiento del cerebro humano. Estas redes se componen de un grupo de nodos conocidos como neuronas, que se agrupan en niveles y se vinculan entre ellos mediante enlaces conocidos como pesos sin√°pticos que pueden ser modificados. Cada neurona acoge se√±ales de entrada, las maneja a trav√©s de una funci√≥n de activaci√≥n y produce una salida que puede ser enviada a otras neuronas en niveles sucesivos [1].

Una red neuronal com√∫n se segmenta en tres componentes b√°sicos. La capa de entrada acoge la informaci√≥n en bruto que ser√° procesada, como pueden ser im√°genes o se√±ales. Las capas encubiertas llevan a cabo c√°lculos y transformaciones no lineales que facilitan a la red el aprendizaje de representaciones intermedias y patrones complicados. Finalmente, la capa de salida proporciona la predicci√≥n definitiva, la cual puede ser una clasificaci√≥n, una probabilidad o un volumen determinado [2].

El proceso de aprendizaje en una red neuronal implica la modificaci√≥n de los pesos de sus conexiones con el fin de reducir la discrepancia entre la salida producida y el valor verdadero anticipado. Este proceso se lleva a cabo a trav√©s de algoritmos de optimizaci√≥n, siendo el algoritmo de retropropagaci√≥n del error (backpropagation) el m√°s empleado. Este calcula la manera en que cada peso debe ser modificado para disminuir el error total [3]. Estas modificaciones est√°n dirigidas por una funci√≥n de p√©rdida, que eval√∫a el grado de error en cada √©poca. Mediante este ciclo de capacitaci√≥n, la red incrementa su habilidad para realizar pron√≥sticos exactos.

Cuando las redes neuronales aumentan su n√∫mero de capas ocultas, se convierten en redes profundas, lo que permite que aprendan representaciones jer√°rquicas de los datos. Las redes profundas han demostrado un desempe√±o sobresaliente en tareas complejas como el reconocimiento de im√°genes, la traducci√≥n autom√°tica y el an√°lisis de voz [1].

#### 1.1.1 Investigaci√≥n te√≥rica: fundamentos y arquitecturas

El estudio de las redes neuronales artificiales tiene sus ra√≠ces en la d√©cada de 1940 con el modelo de McCulloch y Pitts, pero fue reci√©n en los a√±os 80 y 90 que se consolidaron algoritmos como el perceptr√≥n multicapa (MLP) y el backpropagation. Con el avance del hardware y el crecimiento de datasets, se introdujeron arquitecturas m√°s profundas y especializadas.

Entre las arquitecturas m√°s representativas se encuentran:

- **MLP (Multi-Layer Perceptron)**: compuesta por capas totalmente conectadas. Es la base del modelo usado en este proyecto y se caracteriza por transformar entradas vectoriales mediante pesos, biases y funciones de activaci√≥n.
- **CNN (Convolutional Neural Network)**: especializada en el an√°lisis de im√°genes. Utiliza filtros para detectar patrones locales y jer√°rquicos.
- **RNN (Recurrent Neural Network)**: dise√±ada para datos secuenciales, como texto o audio. Posee conexiones recurrentes que permiten conservar memoria del estado anterior.

Para el entrenamiento de estas redes se utiliza el algoritmo de retropropagaci√≥n, propuesto en su forma moderna por Rumelhart, Hinton y Williams (1986), que calcula el gradiente de la funci√≥n de p√©rdida respecto a cada peso mediante la regla de la cadena.

Adem√°s, se requiere un algoritmo de optimizaci√≥n que ajuste los pesos. En este proyecto se usaron dos: **SGD** y **Adam**, seleccionados por su bajo costo computacional y capacidad de adaptaci√≥n a diferentes tasas de aprendizaje, respectivamente.

Esta base te√≥rica permiti√≥ estructurar el desarrollo modular del sistema en C++, reproduciendo comportamientos esenciales del aprendizaje profundo mediante clases y estructuras propias inspiradas en bibliotecas como **PyTorch** y **TensorFlow**.

---

### 1.2 Visi√≥n por Computadora

La visi√≥n computacional es una disciplina de la inteligencia artificial que permite a los ordenadores analizar y procesar im√°genes o v√≠deos con el objetivo de recopilar datos relevantes del entorno [4]. Esta disciplina tiene como objetivo emular la capacidad humana para entender lo que se percibe, pero a trav√©s de algoritmos y esquemas matem√°ticos.

En este proyecto, se utiliza la visi√≥n computacional para examinar im√°genes producidas a partir de un juego de ritmo japon√©s. El sistema tiene que reconocer patrones visuales que simbolizan distintas combinaciones de notas musicales que se descienden por carriles determinados, replicando la experiencia de juegos como *Pop'n Music* o *Beatmania IIDX*.

Para facilitar la interpretaci√≥n de las im√°genes, se utilizan las siguientes t√©cnicas de preprocesamiento:

- **Conversi√≥n a escala de grises**: Este procedimiento elimina la informaci√≥n de color y mantiene √∫nicamente los niveles de intensidad de cada p√≠xel. Seg√∫n Goodfellow, Bengio y Courville [3], esto reduce significativamente la complejidad computacional, ya que la red neuronal trabaja con menos informaci√≥n redundante, centr√°ndose √∫nicamente en los patrones estructurales.

- **Reducci√≥n de tama√±o**: Consiste en disminuir la resoluci√≥n de las im√°genes para optimizar tanto el almacenamiento como la velocidad de procesamiento. Este enfoque es especialmente √∫til cuando se trabaja con grandes vol√∫menes de datos, permitiendo entrenar modelos m√°s r√°pidamente sin sacrificar demasiado la calidad de las caracter√≠sticas relevantes.

- **Normalizaci√≥n**: Hace referencia a incrementar los valores de los p√≠xeles dentro del intervalo [0, 1]. Este procedimiento es esencial para consolidar el proceso de entrenamiento, puesto que contribuye a que las funciones de activaci√≥n y los algoritmos de optimizaci√≥n funcionen de forma m√°s eficaz [3].

---

### 1.3 Generaci√≥n de Datos Sint√©ticos

La generaci√≥n de datos sint√©ticos consiste en la creaci√≥n de ejemplos artificiales mediante algoritmos o modelos matem√°ticos, en lugar de recolectarlos directamente del entorno real [5]. Este enfoque es especialmente √∫til cuando los datos reales son escasos, costosos de adquirir, o presentan restricciones legales y √©ticas relacionadas con la privacidad [6].

En el contexto de este proyecto, se dise√±√≥ un generador en C++ utilizando OpenCV, capaz de sintetizar im√°genes de un juego de ritmo japon√©s con diferentes combinaciones de notas. Las principales ventajas de este m√©todo son:

- **Escalabilidad y costo reducido**: Una vez desarrollado el entorno sint√©tico, es posible generar grandes vol√∫menes de datos de forma autom√°tica y econ√≥mica [7].

- **Etiquetado autom√°tico y exacto**: Cada imagen generada se acompa√±a de etiquetas precisas, lo cual evita errores comunes en el etiquetado manual.

- **Control de variabilidad**: Se puede simular ruido visual, diferentes niveles de dificultad y combinaciones espec√≠ficas, garantizando un dataset robusto frente a condiciones reales [6].

Investigaciones como la realizada por Lu et al. [6] destacan c√≥mo los datos artificiales facilitan la superaci√≥n de los desaf√≠os de calidad y privacidad. Adem√°s, Bauer et al. [7] indican que las herramientas fundamentadas en redes neuronales, como **GANs**, **modelos de difusi√≥n** y **transformers**, permiten el control de la generaci√≥n de datos en contextos complejos.

---

### 1.4 Funciones de Activaci√≥n

Las funciones de activaci√≥n introducen la no linealidad necesaria para que una red neuronal aprenda relaciones complejas entre los datos. Sin estas funciones, la red se comportar√≠a como una combinaci√≥n lineal, lo cual limitar√≠a dr√°sticamente su capacidad de modelado.

- **ReLU (Rectified Linear Unit)**: definida como ùëì(ùë•) = max(0, ùë•), fue introducida originalmente por Kunihiko Fukushima en 1969 [9]. Su uso modernizado en redes profundas se consolid√≥ en 2011 por su capacidad para evitar el problema del gradiente desvanecido, acelerar el aprendizaje y generar activaciones esparsas [10], [11].

- **Softmax**: transforma un vector de valores reales en una distribuci√≥n de probabilidad cuya suma es 1. Est√° relacionada con la distribuci√≥n de Boltzmann en mec√°nica estad√≠stica [12], formalizada en el aprendizaje autom√°tico para clasificaci√≥n multiclase [13]. Es clave en la capa de salida y permite aplicar la entrop√≠a cruzada como funci√≥n de p√©rdida [3].

---

### 1.5 Algoritmos de Optimizaci√≥n

Los algoritmos de optimizaci√≥n son esenciales en el entrenamiento de redes neuronales artificiales, ya que permiten ajustar los pesos de la red con el objetivo de minimizar la funci√≥n de p√©rdida [15].

- **Descenso del Gradiente Estoc√°stico (SGD)**: destaca por su eficiencia computacional al trabajar con mini batches. Sin embargo, puede quedar atrapado en m√≠nimos locales o generar oscilaciones [16].

- **Adam (Adaptive Moment Estimation)**: propuesto por Kingma y Ba [17], combina momentum y RMSProp para ajustar tasas de aprendizaje por par√°metro. Su fortaleza radica en manejar datos complejos y lograr convergencia r√°pida y estable.

**Comparaci√≥n**: Aunque Adam suele ofrecer resultados iniciales superiores, estudios como el de Wilson et al. [18] sugieren que en ciertos casos SGD puede generar soluciones m√°s generalizables a largo plazo.

---

### 1.6 Sobreajuste y T√©cnicas de Regularizaci√≥n

Durante el entrenamiento de una red neuronal, es com√∫n que el modelo se ajuste demasiado a los datos de entrenamiento, lo que reduce su capacidad para generalizar ante datos nuevos. Este fen√≥meno se conoce como **sobreajuste (overfitting)**.

En el presente proyecto, este riesgo implica que el modelo podr√≠a funcionar bien solo con im√°genes iguales a las entrenadas, fallando ante leves variaciones. Por ello, se emplean t√©cnicas de **regularizaci√≥n** para evitarlo y asegurar que el modelo reconozca patrones nuevos con precisi√≥n durante la inferencia.

## Desarrollo de componentes claves:

Para dise√±ar e implementar la red neuronal se incluyeron las siguientes clases para poder simular todo su comportamiento, estas son: Tensor, Activation, Layer, Dense, Loss, Optimizaci√≥n y la clase Neural_Network donde se alojar√°n todas nuestras funciones. A continuaci√≥n se detalla su inclusi√≥n.

En primer lugar, se implement√≥ la clase Tensor.h para manejar toda la informaci√≥n que ingresa a la red neuronal, en estos se incluyen los datos los cuales uno entrenar√° y otro con los valores que desea predecir. El motivo por el cual se escogieron los tensores es para poder trabajar con grandes vol√∫menes de informaci√≥n de forma eficiente, debido a que estos se componen principalmente de datos binarios. Los modelos aumentan en complejidad y tama√±o, los puntos de control distribuidos se convierten en un componente crucial del proceso de entrenamiento. No obstante estos suelen generar importantes demandas de almacenamiento. Para abordar este desaf√≠o, la comprensi√≥n surge como una soluci√≥n natural. Dado que los puntos de control se componen principalmente de datos binarios (tensores)[23]. Es por ello que para desarrollar esta clase tomamos como referencia la biblioteca Pytorch.

En esta biblioteca trabajamos simulando los distintos m√©todos de operaciones con matrices como por ejemplo la funci√≥n de transposici√≥n, multiplicaci√≥n escalar, tensor broadcasting, lo cual permiti√≥ operar entre tensores de distintas dimensiones respetando reglas similares a las de bibliotecas como Numpy. 

En el marco del proyecto, esto fue crucial para poder representar correctamente tanto las im√°genes de entrada generadas a partir de combinaciones de notas del videojuego Pop‚Äôn Music, como tambi√©n los pesos y salidas de cada capa de la red neuronal. Esta implementaci√≥n ayuda durante el entrenamiento del modelo, por ejemplo en la aplicaci√≥n aplicar gradientes y operaciones de retropropagaci√≥n de manera controlada y precisa. 

Las clases layers son las capas que conectadas entre s√≠, hacen posible que funcione el proceso de entrenamiento. Hay tres partes donde se presentan estas capas: Una capa de entrada, donde se ingresa los valores iniciales del entrenamiento; las capas ocultas, donde se realiza todo el proceso de c√°lculo y ponderaci√≥n; por √∫ltimo la capa de salida con los valores de destino que se busca en el entrenamiento. Durante todas estas capas se busca que cada valor inicial que ingrese se procese dentro de las capas ocultas con ponderaciones aleatorias que se van actualizando gradualmente para acercarlas a la capa de destino. Este proceso sigue su curso hasta un punto en que varias capas coincidan con la salida; es decir, tengan valores esperados [29]. La generaci√≥n de las capas tienen dos m√©todos como forward, utilizado para generar un resultado en cada capa acorde al valor anterior que tiene y backward para obtener los valores de los errores en la gradiente en cada capa respecto a los pesos de cada capa. Esto para hacer el proceso de "back propagation". La utilidad de ello es para la actualizaci√≥n de los pesos y continuar con el modelo del entrenamiento.

En tercer lugar se incluy√≥ la clase Dense para conectar cada una de nuestras capas, tambi√©n conocida como capa completamente conectada. Su funci√≥n principal es realizar una transformaci√≥n lineal de la entrada mediante multiplicaci√≥n de matrices y suma de un bias, antes de aplicar la funci√≥n de activaci√≥n. En esta capa cada nodo est√° conectado a todos los nodos de la capa anterior [28]. Este tipo de capa, es utilizada para que en cada uno de los datos de salida, su c√°lculo sea dado como resultado de la suma de todos los nodos de las capas anteriores por sus respectivos pesos m√°s un sesgo. De esta manera en cada parte del entrenamiento los pesos modificados influir√°n en cada de uno de los resultados. La funci√≥n de activaci√≥n ¬´f¬ª envuelve el producto escalar entre la entrada de la capa y su matriz de ponderaciones. Tenga en cuenta que las columnas de la matriz de ponderaciones tendr√≠an valores diferentes y se optimizar√≠an durante el entrenamiento del modelo [25].
En tercer lugar, la clase Dense implementa una capa totalmente conectada, uno de los elementos fundamentales en redes neuronales artificiales.

Dentro del proyecto, esta clase se encarga de transformar los datos que representan los patrones visuales del videojuego Pop‚Äôs Music en representaciones intermedias que pueden ser interpretadas por las siguientes capas. Es decir, permite que la red entienda las combinaciones de notas a trav√©s del aprendizaje de pesos y sesgos. De este modo, la clase contiene los siguientes elementos clave: 

- `W` y `b`: representan los pesos y sesgos de la capa. Son inicializados con funciones externas y actualizados durante el entrenamiento. 
- `dW` y `db`: almacenan las gradientes de los pesos y sesgos, calculados durante la retropropagaci√≥n. 
- `forward()`: recibe una entrada `x`, calcula `xW·µó + b` y devuelve el resultado. Esta operaci√≥n transforma la entrada para que sea procesada por la siguiente capa.
- `backward()`: calcula los gradientes (`dW`, `db`) usando la derivada de la p√©rdida con respecto a la salida de esta capa (`dZ`). Luego, devuelve el gradiente respecto a la entrada para continuar la retropropagaci√≥n.
- `update_params()`: utiliza un optimizador (`SGD`, `Adam`, etc.) para ajustar los pesos `W` y sesgos `b` en funci√≥n de los gradientes.

De esta manera, la red neuronal puede aprender una representaci√≥n abstracta de las im√°genes de entrada y adaptarse a patrones complejos en los datos generados por el entorno de Pop‚Äôn Music. 

En cuarto lugar, las funciones de activaci√≥n son fundamentales para introducir no linealidad en el modelo, lo que permite que la red aprenda patrones complejos y represente relaciones no triviales en los datos.

En el marco del proyecto, estas funciones permiten que la red reaccione de manera diferenciada seg√∫n las combinaciones de notas detectadas. La activaci√≥n correcta en cada capa mejora significativamente la capacidad de clasificaci√≥n del modelo. Para este proceso, se usa cuatro clases:

- **ReLU (Rectified Linear Unit)**: eval√∫a cada dato de entrada y lo deja igual si es mayor que 0, o lo convierte en 0 si es negativo. Es ideal para capas ocultas debido a su eficiencia computacional y porque ayuda a mitigar el problema del gradiente desvanecido, un fen√≥meno que ocurre cuando los gradientes utilizados para actualizar los pesos se vuelven tan peque√±os que impiden el aprendizaje efectivo en redes profundas [28]. Este problema puede detener por completo el entrenamiento, especialmente en modelos con muchas capas. El uso de ReLU permite que los gradientes se mantengan estables, acelerando el proceso de aprendizaje y evitando que se ‚Äúapague‚Äù la red.

- **Sigmoid**: transforma cada valor en una probabilidad entre 0 o 1, lo cual es √∫til para tareas de clasificaci√≥n binaria o como activaci√≥n en capas de salida con decisiones dicot√≥micas.

- **Softmax**: convierte los valores de salida en una distribuci√≥n de probabilidad sobre m√∫ltiples clases. Es utilizada al final del modelo, donde cada patr√≥n visual puede pertenecer a una clase distinta.

Cada una de estas funciones de activaci√≥n hereda de `ILayer<T>` e implementa los m√©todos `forward()` y `backward()`


En quinto lugar, la clase Neural Network act√∫a como el n√∫cleo de aprendizaje profundo, ya que permite organizar, entrenar, evaluar y guardar toda la arquitectura construida con capas. En el marco del proyecto, esta clase coordina el aprendizaje de patrones visuales complejos, reconociendo combinaciones espec√≠ficas de notas que definen el input del jugador. A continuaci√≥n se presentan las funcionalidades que se requieren para este aprendizaje: 

- `add_layer()`: permite a√±adir nuevas capas de manera secuencial al modelo. Esto permite construir arquitecturas flexibles que combinan transformaciones lineales (`Dense`) y no lineales (`ReLU`, `Softmax`), necesarias para el aprendizaje jer√°rquico de los datos.
- `predict()`: realiza la propagaci√≥n hacia adelante (*forward propagation*) de una entrada a trav√©s de todas las capas del modelo, produciendo una predicci√≥n final. En el contexto del juego, esto se traduce en una decisi√≥n del modelo respecto a qu√© clase pertenece una determinada imagen del patr√≥n musical.
- `train()`: entrena la red usando un algoritmo de retropropagaci√≥n con descenso del gradiente. En cada √©poca:
  - Divide los datos en mini-lotes (`batch_size`).
  - Propaga cada mini-lote con `predict()`.
  - Calcula el error usando una funci√≥n de p√©rdida (`LossType`).
  - Retropropaga el gradiente con `backward()` y actualiza los par√°metros con un optimizador (`OptimizerType`, por defecto `SGD`).
  - Mide la p√©rdida y la precisi√≥n (*accuracy*) tras cada √©poca.
- `save()` y `load()`: permiten guardar y restaurar el estado del modelo entrenado. Esto resulta fundamental para no tener que reentrenar el modelo desde cero al reiniciar el juego, y poder cargar una red ya entrenada que reconozca los patrones.

Gracias a esta clase, el videojuego puede aprender a partir de los datos de entrenamiento y generalizar el reconocimiento de nuevas combinaciones de notas. Esto permite construir una experiencia interactiva m√°s robusta, donde el modelo comprende patrones sin necesidad de ser programado expl√≠citamente para cada combinaci√≥n. 

En quinto lugar la clase Loss define las funciones de p√©rdida utilizadas durante el entrenamiento de la red neuronal. Estas funciones son importantes debido a que permiten calcular la diferencia entre las predicciones generadas por el modelo y los valores esperados. En el contexto del presente proyecto, que busca entrenar una red neuronal capaz de reconocer patrones visuales del videojuego Pop‚Äôn Music, la presente clase cumple un rol fundamental en el aprendizaje autom√°tico. As√≠, este m√≥dulo define las funciones de p√©rdida que permiten cuantificar que tan acertada es la predicci√≥n del modelo al clasificar una imagen generada con combinaciones de notas respecto a su etiqueta real. 
Durante el entrenamiento de la red neuronal, al mostrarle una imagen que representa una secuencia del juego, se compara la salida predicha con la etiqueta correcta. La funci√≥n de p√©rdida mide esta diferencia, devolviendo un valor num√©rico que indica cu√°n lejos estuvo la predicci√≥n del resultado esperado. En este caso, la clase incluye tres implementaciones especializadas: MSELoss, √∫til para tareas de regresi√≥n; BCELoss, aplicada cuando se trata de decisiones binarias; CrossEntropyLoss, m√°s utilizada debido a que el modelo realiza una clasificaci√≥n multiclase entre los diferentes tipos de combinaciones posibles en las im√°genes del juego. 
De este modo, cada una de estas funciones de p√©rdida implementa dos m√©todos clave: loss(), que devuelve el valor de error, y loss_gradient(), que permite retropropagar dicho error para ajustar los pesos de la red. Gracias a esta retroalimentaci√≥n, el modelo mejora su precisi√≥n en la clasificaci√≥n de nuevos patrones generados a partir del entorno visual de Pop‚Äôn Music. 

En sexto lugar, la clase Optimizaci√≥n se utiliza para implementar los algoritmos de optimizaci√≥n que se encargan de actualizar los pesos de la red neuronal durante el proceso de entrenamiento. Para el presente proyecto, estos algoritmos permiten que la red aprenda a clasificar correctamente los patrones al minimizar el valor de la funci√≥n p√©rdida. El archivo define dos optimizadores fundamentales: 
- `SGD` (Stochastic Gradient Descent): se trata de un optimizador cl√°sico que ajusta cada peso restando una fracci√≥n proporcional a su gradiente. Su simplicidad lo hace r√°pido, pero puede tener dificultades en converger cuando el espacio de par√°metros es irregular o tiene muchos m√≠nimos locales. 
- `Adam` (Adaptive Moment Estimation): es un optimizador m√°s sofisticado que combina el enfoque de momento y adaptaci√≥n de tasa de aprendizaje. Almacena promedios m√≥viles de los gradientes (primer momento m) y de sus cuadrados (segundo momento v) y los corrige en cada paso de actualizaci√≥n.  Esto permite una convergencia m√°s r√°pida y estable, especialmente √∫til en entornos como el nuestro donde los datos visuales pueden ser ruidosos o variados.

Ambas clases implementan el m√©todo update(), que recibe los par√°metros actuales y sus respectivos gradientes, y luego los actualiza con base en la l√≥gica del optimizador correspondiente. 

En s√©ptimo lugar se implement√≥ un archivo denominado ‚Äúinterfaces‚Äù que define las interfaces principales que sirven como base para el dise√±o modular de toda la red neuronal implementada. Estas interfaces permiten separar responsabilidades entre capas, funciones de p√©rdida y optimizadores, facilitando que cada componente sea reutilizable e intercambiable en distintos contextos. 
La interfaz ILayer<T> es implementada por todas las capas del modelo, incluyendo las densas (Dense) y las de activaci√≥n (ReLU, Sigmoid, Softmax). Esta interfaz obliga a definir dos funciones principales:
- `forward()`: se encarga de propagar los datos de entrada hacia adelante, capa por capa.
- `backward()`: se utiliza en la retropropagaci√≥n del error para ajustar los pesos en funci√≥n de los gradientes.
- `update_params()`: m√©todo opcional que permite actualizar los par√°metros entrenables como pesos y sesgos cuando corresponde.
Por otro lado, la interfaz ILoss<T, DIMS> define el comportamiento de las funciones de p√©rdida como CrossEntropyLoss. Estas funciones permiten medir cu√°n lejos est√°n las predicciones del modelo respecto a las etiquetas reales. Esta interfaz exige definir el m√©todo loss(), que calcula el error de predicci√≥n, y loss_gradient(), que genera el gradiente necesario para que la red aprenda durante el entrenamiento.
Finalmente, la interfaz IOptimizer<T> es implementada por optimizadores como SGD o Adam, y se encarga de actualizar los pesos y sesgos del modelo seg√∫n los gradientes calculados. En nuestro caso, permite que la red neuronal aprenda a clasificar correctamente los patrones visuales asociados a combinaciones musicales, ajustando los par√°metros despu√©s de cada retropropagaci√≥n.

Por √∫ltimo, la clase NeuralNetwork representa el modelo principal de red neuronal que orquesta el flujo completo de datos a trav√©s de todas las capas definidas y permite entrenar, predecir y guardar/cargar el modelo. As√≠, act√∫a como el n√∫cleo funcional del sistema inteligente. Sus principales funcionales se divide en las siguientes partes: 
- `add_layer`: permite ir agregando las capas (como Dense, ReLU, Softmax, etc.) de forma modular. As√≠, se puede dise√±ar la arquitectura del modelo de manera flexible y personalizada para nuestro juego.
- `predict`: ejecuta una propagaci√≥n hacia adelante (forward) pasando la entrada por todas las capas agregadas. Esto es usado tanto durante el entrenamiento como durante la etapa de inferencia, cuando se desea predecir la clase correspondiente a una nueva entrada musical.
- `train`: realiza el proceso de entrenamiento mediante:
  - La generaci√≥n de batches con los datos de entrada y etiquetas.
  - El c√°lculo de la predicci√≥n usando predict.
  - La evaluaci√≥n del error con una funci√≥n de p√©rdida (como CrossEntropyLoss).
  - La retropropagaci√≥n del gradiente con backward
La actualizaci√≥n de pesos con el optimizador (SGD por defecto).
Este entrenamiento se realiza por varias √©pocas, lo que permite que el modelo aprenda progresivamente a clasificar correctamente las combinaciones musicales.
- `save/load`: implementa funciones para guardar y cargar los pesos del modelo entrenado. As√≠ se evita tener que entrenarlo cada vez, y se puede reutilizar en futuras sesiones del juego.

Es as√≠ como gracias a esta clase,todo el sistema de entrenamiento y evaluaci√≥n est√° encapsulado en un solo objeto, lo que permite entrenar y reutilizar modelos completos de manera eficiente. En el contexto del proyecto, esta clase facilita el reconocimiento preciso de patrones musicales, mejorando progresivamente su capacidad predictiva con cada √©poca de entrenamiento.


### 2. Dise√±o e implementaci√≥n

#### 2.1 Arquitectura de la soluci√≥n

* **Patrones de dise√±o**: ejemplo: Factory para capas, Strategy para optimizadores.
* **Estructura de carpetas (ejemplo)**:

  ```
  proyecto-final/
  ‚îú‚îÄ‚îÄ generator/	              #Generador de im√°genes de entrada tipo juego r√≠tmico
  |   ‚îú‚îÄ‚îÄ assets/              #Recursos visuales: pop-kuns y plantillas
  |   |	‚îú‚îÄ‚îÄ kuns/
  |   |	|   ‚îú‚îÄ‚îÄ blue.png
  |   |	|   ‚îú‚îÄ‚îÄ green.png
  |   |	|   ‚îú‚îÄ‚îÄ red.png
  |   |	|   ‚îú‚îÄ‚îÄ white.png
  |   |	|   ‚îî‚îÄ‚îÄ yellow.png
  |   |	‚îú‚îÄ‚îÄ halo.png
  |   |	‚îú‚îÄ‚îÄ halo_smaller.png
  |   |	‚îú‚îÄ‚îÄ empty_template.png
  |   |	‚îú‚îÄ‚îÄ empty_template_smaller.png
  |   |   ‚îú‚îÄ‚îÄ template.png
  |   |   ‚îî‚îÄ‚îÄ template_smaller.png
  |   ‚îî‚îÄ‚îÄ main.cpp             #C√≥digo para la generaci√≥n visual
  ‚îú‚îÄ‚îÄ include/                 #Headers del proyecto
  ‚îÇ   ‚îú‚îÄ‚îÄ utec/
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ algebra/         #Implementaci√≥n del tensor personalizado
  ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tensor.h
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nn/              #M√≥dulos de red neuronal
  ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ neural_network.h
  ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nn_activation.h
  ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nn_dense.h
  ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nn_interfaces.h
  ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nn_loss.h
  ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nn_optimizer.h
  ‚îú‚îÄ‚îÄ src/                     #Entrada principal del programa entrenable
  ‚îÇ   ‚îî‚îÄ‚îÄ main.cpp
  ‚îú‚îÄ‚îÄ tests/                   #Evaluadores por lote, juego y por imagen
  ‚îÇ   ‚îú‚îÄ‚îÄ batch_evaluator/
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ src/main.cpp
  ‚îÇ   ‚îú‚îÄ‚îÄ gameplay_evaluator/
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ src/main.cpp
  ‚îÇ   ‚îî‚îÄ‚îÄ image_evaluator/
  ‚îî‚îÄ‚îÄ ‚îÇ   ‚îî‚îÄ‚îÄ src/main.cpp
  ```

#### 2.2 Manual de uso y casos de prueba

* **C√≥mo ejecutar**: `./build/neural_net_demo input.csv output.csv`
* **Casos de prueba**:

  * Test unitario de capa densa.
  * Test de funci√≥n de activaci√≥n ReLU.
  * Test de convergencia en dataset de ejemplo.

> *Personalizar rutas, comandos y casos reales.*

---

### 3. Ejecuci√≥n

> **Demo de ejemplo**: Video/demo alojado en `docs/demo.mp4`.
> Pasos:
>
> 1. Preparar datos de entrenamiento (formato CSV).
> 2. Ejecutar comando de entrenamiento.
> 3. Evaluar resultados con script de validaci√≥n.

---

### 4. An√°lisis del rendimiento

* **M√©tricas de ejemplo**:

  * Iteraciones: 150 √©pocas.
  * Tiempo total de entrenamiento: 1h03m15s.
  * Precisi√≥n final: 92.5%.
* **Ventajas/Desventajas**:
  * * C√≥digo efectivo para el entrenamiento.
  * * Uso adecuado de la funci√≥n de perdida.
  * * Uso de hilos que facilitan los calculos para el entreamiento.

  * ‚Äì Sin optimizaciones num√©ricas.
* **Mejoras futuras**:

  * Incorporar el uso de BLAS (Basic Linear Algebra Subprograms) para operaciones matriciales, como la multiplicaci√≥n de matrices en capas densas.
  * Incorporar algoritmos de optimizaci√≥n m√°s avanzados, como Gradiente Descendente con Momentum. La raz√≥n de esto es que el optimizador actual (SGD) actualiza los pesos solo con base en el gradiente actual, lo que puede generar oscilaciones en regiones de la funci√≥n de p√©rdida con mucha curvatura o valles largos. Y el uso de momentum agrega una fracci√≥n del gradiente anterior al gradiente actual, permitiendo avanzar m√°s r√°pido en direcciones consistentes y amortiguar oscilaciones.

---

## 5. Trabajo en equipo

| **Tarea**                    | **Miembro**                             | **Rol**                         |
|-----------------------------|-----------------------------------------|---------------------------------|
| Investigaci√≥n te√≥rica       | Matos Copello Rayhan Derek              | Documentar bases te√≥ricas       |
| Investigaci√≥n te√≥rica       | Tamara Ureta, Anyeli Azumi              | Documentar bases te√≥ricas       |
| Dise√±o e implementaci√≥n     | Alvarado Le√≥n, Adriana Celeste          | UML y esquemas de clases        |
| Implementaci√≥n del modelo   | Mattos Gutierrez, Angel Daniel          | C√≥digo C++ de la NN             |
| An√°lisis y rendimiento      | Aquino Castro Farid Jack                | Generaci√≥n de m√©tricas          |
| Documentaci√≥n y demo        | Portugal Vilca Julio Cesar              | Tutorial y video demo           |

---

### 6. Conclusiones

* **Logros:**  Se llev√≥ a cabo con √©xito una red neuronal desde el inicio en C++, incluyendo elementos como tensores, funciones de activaci√≥n, p√©rdida y optimizaci√≥n, y se comprob√≥ su rendimiento en un dataset sint√©tico creado autom√°ticamente.

* **Resultados:**  El modelo logr√≥ una exactitud que super√≥ el 99% en validaciones por lotes y demostr√≥ habilidad para generalizar al implementarse en situaciones reales en el videojuego Pop‚Äôn Music.

 * **Aprendizaje:**  Se profundiz√≥ en aspectos fundamentales del aprendizaje profundo como la retropropagaci√≥n, la normalizaci√≥n de entradas, la inicializaci√≥n de pesos y la modificaci√≥n de hiperpar√°metros en ambientes de nivel bajo sin frameworks externos.

 * **Sugerencias:**  Para futuras mejoras, se recomienda expandirse a datasets m√°s complejos y diversos, incorporar entrenamiento con GPU (CUDA) para disminuir los tiempos computacionales, y aplicar m√©todos adicionales como la normalizaci√≥n y normalizaci√≥n en grupo.

---

## 7. Referencias Bibliogr√°ficas

[1] J. Schmidhuber, "Deep Learning in Neural Networks: An Overview," Neural Networks, vol. 61, pp. 85‚Äì117, 2015.  
[2] R. Zhang, W. Li, and T. Mo, "Review of Deep Learning," arXiv preprint arXiv:1804.01653, 2018.  
[3] I. Goodfellow, Y. Bengio, and A. Courville, *Deep Learning*. MIT Press, 2016.  
[4] R. Szeliski, *Computer Vision: Algorithms and Applications*. Springer, 2010.  
[5] The Royal Society and The Alan Turing Institute, "Synthetic Data: What, Why and How?," The Royal Society, 2021.  
[6] Y. Lu, M. Shen, H. Wang, et al., "Machine Learning for Synthetic Data Generation: A Review," arXiv preprint arXiv:2305.15799, 2023.  
[7] A. Bauer, S. Trapp, M. Stenger, et al., "Comprehensive Exploration of Synthetic Data Generation: A Survey," arXiv preprint arXiv:2401.03067, 2024.  
[8] M. Giuffr√® and D. L. Shung, "Harnessing the Power of Synthetic Data in Healthcare: Innovation, Application, and Privacy," *npj Digital Medicine*, vol. 6, no. 186, 2023. doi: 10.1038/s41746-023-00927-3.  
[9] K. Fukushima, "Visual feature extraction by a multilayered network of analog threshold elements," *IEEE Trans. Systems Science and Cybernetics*, vol. 5, no. 4, pp. 322‚Äì333, 1969.  
[10] K. Jarrett, K. Kavukcuoglu, M. A. Ranzato, and Y. LeCun, "What is the Best Multi-Stage Architecture for Object Recognition?," in *2009 IEEE 12th International Conference on Computer Vision*, 2009, pp. 2146‚Äì2153. doi: 10.1109/ICCV.2009.5459469.  
[11] X. Glorot, A. Bordes, and Y. Bengio, "Deep sparse rectifier neural networks," in *Proc. 14th Int. Conf. Artif. Intell. Statist. (AISTATS)*, 2011, pp. 315‚Äì323.  
[12] L. Boltzmann, "Studien √ºber das Gleichgewicht der lebendigen Kraft zwischen bewegten materiellen Punkten," *Wiener Berichte*, vol. 58, pp. 517‚Äì560, 1868.  
[13] J. W. Gibbs, *Elementary Principles in Statistical Mechanics*. Yale University Press, 1902.  
[14] V. Shatravin, D. Shashev, and S. Shidlovskiy, "Implementation of the SoftMax Activation for Reconfigurable Neural Network Hardware Accelerators," *Applied Sciences*, vol. 13, no. 23, 2023. doi: 10.3390/app132312784.  
[15] S. Ruder, "An overview of gradient descent optimization algorithms," arXiv preprint arXiv:1609.04747, 2017.  
[16] L. Bottou, "Large-Scale Machine Learning with Stochastic Gradient Descent," in *Proceedings of COMPSTAT'2010*, Springer, 2010, pp. 177‚Äì186. doi: 10.1007/978-3-7908-2604-3_16.  
[17] D. P. Kingma and J. Ba, "Adam: A method for stochastic optimization," arXiv preprint arXiv:1412.6980, 2014.  
[18] A. C. Wilson, R. Roelofs, M. Stern, N. Srebro, and B. Recht, "The marginal value of adaptive gradient methods in machine learning," in *Advances in Neural Information Processing Systems (NeurIPS)*, 2017.  
[19] J. Brownlee, ‚ÄúRectified Linear Activation Function for Deep Learning Neural Networks,‚Äù *Machine Learning Mastery*, 2019. [Online]. Available: https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/  
[20] DataCamp, ‚ÄúWhat is ReLU? The Rectified Linear Unit Activation Function,‚Äù *DataCamp Blog*, 2023. [Online]. Available: https://www.datacamp.com/blog/rectified-linear-unit-relu  
[21] OldGameShelf, ‚ÄúPop‚Äôn Music GB (GBC),‚Äù *OldGameShelf.com*, [Online]. Available: https://oldgameshelf.com/es/games/gbc/pop%27n-music-gb-gbc-6719  
[22] Deepchecks, ‚ÄúRectified Linear Unit (ReLU),‚Äù *Deepchecks Glossary*, 2023. [Online]. Available: https://www.deepchecks.com/glossary/rectified-linear-unit-relu/  
[23] PyTorch, ‚ÄúReducing storage footprint and bandwidth usage for distributed checkpoints with PyTorch DCP,‚Äù *PyTorch Blog*, 2023. [Online]. Available: https://pytorch.org/blog/reducing-storage-footprint-and-bandwidth-usage-for-distributed-checkpoints-with-pytorch-dcp/  
[24] Analytics Vidhya, ‚ÄúIntroduction to Softmax for Neural Network,‚Äù *Analytics Vidhya*, 2021. [Online]. Available: https://www.analyticsvidhya.com/blog/2021/04/introduction-to-softmax-for-neural-network/  
[25] Built In, ‚ÄúWhat Is a Fully Connected Layer?,‚Äù *builtin.com*, [Online]. Available: https://builtin.com/machine-learning/fully-connected-layer  
[26] Nerdjock, ‚ÄúDeep Learning Course Lesson 5: Forward and Backward Propagation,‚Äù *Medium*, 2020. [Online]. Available: https://medium.com/@nerdjock/deep-learning-course-lesson-5-forward-and-backward-propagation-ec8e4e6a8b92  
[27] KeepCoding, ‚ÄúForward y Back Propagation en Deep Learning,‚Äù *KeepCoding.io*, [Online]. Available: https://keepcoding.io/blog/forward-back-propagation-deep-learning/  
[28] Universidad de Guadalajara, ‚ÄúCapas de una red neuronal,‚Äù *CUCSur UDGVirtual*, 2024. [Online]. Available: http://cucsur.udgvirtual.udg.mx/oa/2024/RedesNeu/capas.html
[29] IBM, ‚ÄúNeural network model,‚Äù IBM Documentation, [Online]. Available: https://www.ibm.com/docs/en/spss-modeler/saas?topic=networks-neural-model. [Accessed: Jul. 10, 2025].

### Licencia

Este proyecto usa la licencia **MIT**. Ver [LICENSE](LICENSE) para detalles.

---
